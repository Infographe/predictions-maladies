from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import dill
import numpy as np
import os
import logging
from fastapi.middleware.cors import CORSMiddleware

# üîπ Configuration des logs
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# V√©rifier si le mod√®le existe avant de le charger
model_path = "models/average_model.pkl"

if not os.path.exists(model_path):
    raise FileNotFoundError(f"‚ùå Mod√®le non trouv√© : {model_path}. Ex√©cutez 'train_model.py' pour le g√©n√©rer.")

# Charger le mod√®le avec gestion des erreurs
try:
    with open(model_path, "rb") as f:
        model = dill.load(f)
    logger.info(f"‚úÖ Mod√®le charg√© avec succ√®s depuis {model_path}")
except Exception as e:
    raise RuntimeError(f"Erreur lors du chargement du mod√®le : {str(e)}")

# Cr√©ation de l'API
app = FastAPI()

# üîπ Gestion des permissions CORS (Autoriser toutes les requ√™tes)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# D√©finition des entr√©es pour la pr√©diction
class PredictionInput(BaseModel):
    feature1: float
    feature2: float
    feature3: float
    feature4: float
    feature5: float

@app.post("/predict")
def predict(data: PredictionInput):
    """
    Prend une requ√™te avec 5 features et retourne une pr√©diction.
    """
    try:
        features = np.array([[data.feature1, data.feature2, data.feature3, data.feature4, data.feature5]])
        prediction = model.predict(features)[0]
        logger.info(f"üîç Pr√©diction effectu√©e : {prediction}")
        return {"prediction": float(prediction)}
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la pr√©diction : {str(e)}")
        raise HTTPException(status_code=500, detail="Erreur interne du serveur lors de la pr√©diction.")
